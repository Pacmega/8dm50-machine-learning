{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "\n",
    "## Dataset\n",
    "\n",
    "In this set of exercises we will use the same dataset as from [week 3](week_3.ipynb). \n",
    "\n",
    "\n",
    "As before, we provide the data already curated in the following two files:\n",
    "\n",
    "`RNA_expression_curated.csv`: [148 cell lines , 238 genes]\n",
    "\n",
    "`drug_response_curated.csv`: [148 cell lines , YM155 drug]\n",
    "\n",
    "The curated data can be read as `pandas` `DataFrame` in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gene_expression = pd.read_csv(\"/Users/Utilizador/Desktop/8dm50-machine-learning-master/practicals/data/RNA_expression_curated.csv\", sep=',', header=0, index_col=0)\n",
    "drug_response = pd.read_csv(\"/Users/Utilizador/Desktop/8dm50-machine-learning-master/practicals/data/drug_response_curated.csv\", sep=',', header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the exercises is to train support vector machine (SVM) and random forests classifiers on this dataset and explore and learn about their hyperparameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "The `scikit-learn` library provides the required tools for support vector machines, as well as for random forest algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_blobs, make_circles\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, look up the documentation of the imported functions and read about their basic functionality. Below, we list some important parameters of SVMs and random forests that can be tuned during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines (SVM)\n",
    "\n",
    "`C`: error term.\n",
    "\n",
    "`kernel`: similarity function ('linear', 'poly', 'sigmoid' or 'rbf')\n",
    "\n",
    "`gamma`: kernel coef. for 'rbf', 'poly' and 'sigmoid' kernels. It can be thought of as the ‘spread’ of the kernel and therefore the decision region.\n",
    "\n",
    "`degree`: degree for the 'poly' kernel.\n",
    "\n",
    "`coef0`: independt term in the 'poly' and 'sigmoid' kernels\n",
    "\n",
    "\n",
    "#### Random Forests\n",
    "\n",
    "`n_estimators`: number of trees in our random forest.\n",
    "\n",
    "`max_depth`: maximum number of levels in each decision tree\n",
    "\n",
    "`max_features`: maximum number of features to consider per split in an individual tree.\n",
    "\n",
    "`min_sample_leaf`: minimum number of data points per leaf node\n",
    "\n",
    "`min_samples_split`: minimum number of data points placed in a node before the node is split\n",
    "\n",
    "`oob_score`: the out-of-bag (OOB) error is the average error for each observation calculated using predictions from the trees that do not contain that observation in their respective bootstrap sample. Set this parameter to true.\n",
    "\n",
    "`bootstrap`: method for sampling data points (with or without replacement). Set this parameter to true.\n",
    "\n",
    "`criterion`: function used to measure the quality of the split (e.g. 'entropy' or 'gini')\n",
    "\n",
    "# Exercises\n",
    "\n",
    "## Support vector machines\n",
    "\n",
    "The  `make_blobs` and `make_circles` functions can be used to generate linearly and not linearly separable toy datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generation: linearly separable\n",
    "X, Y = make_blobs(n_samples=200, centers=2, n_features=2, random_state=1234)\n",
    "X = pd.DataFrame(X, columns=['x1', 'x2'])\n",
    "\n",
    "# splitting data into training and test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=333)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code illustrates how to train a linear SVM classifier and plot the data points, the separating hyperplane, the support vectors and the margins that pass through them (considering the training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# build the model\n",
    "model = svm.SVC(kernel='linear', random_state=33)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# create plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# get colors from qualitative colormap 'Paired'\n",
    "cmap = plt.cm.get_cmap('Paired')\n",
    "\n",
    "# plot data points\n",
    "ax.scatter(X_train.iloc[Y_train == 1, 0], X_train.iloc[Y_train == 1, 1],\n",
    "           c=[cmap(11)], label='1')\n",
    "ax.scatter(X_train.iloc[Y_train == 0, 0], X_train.iloc[Y_train == 0, 1],\n",
    "           c=[cmap(0)], label='0')\n",
    "ax.legend(loc='best')\n",
    "\n",
    "# plot the decision function\n",
    "# create grid to evaluate model\n",
    "x1_min, x1_max = X_train.iloc[:, 0].min() - 1, X_train.iloc[:, 0].max() + 1\n",
    "x2_min, x2_max = X_train.iloc[:, 1].min() - 1, X_train.iloc[:, 1].max() + 1\n",
    "\n",
    "XX, YY = np.meshgrid(np.arange(x1_min, x1_max, .2),\n",
    "                     np.arange(x2_min, x2_max, .2))\n",
    "\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = model.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "# plot decision boundary and margins\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5,\n",
    "           linestyles=['--', '-', '--'])\n",
    "\n",
    "# Establish the class for each point in the contour\n",
    "Z = model.predict(xy).reshape(XX.shape)\n",
    "\n",
    "# Visualization of the contour\n",
    "ax.contourf(XX, YY, Z, cmap='bwr', alpha=0.3)\n",
    "\n",
    "# plot support vectors, whose are responsible for building the margins\n",
    "ax.scatter(model.support_vectors_[:, 0], model.support_vectors_[:, 1], s=100,\n",
    "           linewidth=1, facecolors='none', edgecolors='k', marker='s')\n",
    "\n",
    "ax.axis([x1_min, x1_max, x2_min, x2_max])\n",
    "plt.axis('tight')\n",
    "plt.title('Linear kernel SVM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a radial basis function (RBF) SVM classifier with `gamma=0.5` and plot the results in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generation: not linearly separable\n",
    "X, Y = make_circles(n_samples=200, noise=0.05, random_state=1234)\n",
    "X = pd.DataFrame(X, columns=['x1', 'x2'])\n",
    "\n",
    "# splitting data into training and test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=333)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font color='#770a0a'>When should a RBF kernel be used over a linear kernel? Motivate your answer.</font></p>\n",
    "\n",
    "<p><font color='#770a0a'>Do we need to normalize the data before using a kernel function? Motivate your answer.\n",
    "</font></p>\n",
    "\n",
    "Yes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting drug response on cell lines from gene expression data with SVMs\n",
    "\n",
    "Explore the hyper-parameter space of an SVM classifier with cross-validation for the Genomics of Drug Sensitivity in Cancer (GDSC) dataset. The`GridSearchCV` function can be used to specify a grid of parameter values with the `param_grid` parameter.\n",
    "\n",
    "Calculate the precision of your predictions, and compare your calculations with the results of `classification_report`, which displays many classification metrics.\n",
    "\n",
    "\n",
    "## Random forests\n",
    "\n",
    "Follow the same steps as for SVM. Compare the two algorithms and report which one has better performance.\n",
    "\n",
    "The random forests classifiers allows to perform feature selection. Evaluate the importance of features extracting the top 50 informative features. A bar plot (`plt.bar()`) can be a useful tool to visualize this. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gene_expression = pd.read_csv(\"/Users/Utilizador/Desktop/8dm50-machine-learning-master/practicals/data/RNA_expression_curated.csv\", sep=',', header=0, index_col=0)\n",
    "drug_response = pd.read_csv(\"/Users/Utilizador/Desktop/8dm50-machine-learning-master/practicals/data/drug_response_curated.csv\", sep=',', header=0, index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_blobs, make_circles\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_mean = drug_response.YM155.mean()\n",
    "categorical_y = [1 if response > response_mean else 0 \\\n",
    "                 for response in drug_response.YM155]\n",
    "\n",
    "gene_train, gene_test, drug_train, drug_test = train_test_split(gene_expression, categorical_y, \n",
    "                                                                train_size = 0.75, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline = Pipeline([('imputer', Imputer()), \n",
    "                # ('clf', RandomForestClassifier(warm_start=True))])\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", RandomForestClassifier())\n",
    "])\n",
    "\n",
    "pipeline.fit(gene_train,drug_train)\n",
    "prediction=pipeline.predict(gene_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__max_depth</th>\n",
       "      <th>param_clf__max_features</th>\n",
       "      <th>param_clf__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.314154</td>\n",
       "      <td>0.006339</td>\n",
       "      <td>0.033314</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'clf__max_depth': 1, 'clf__max_features': 0.1...</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.720721</td>\n",
       "      <td>0.055535</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.895245</td>\n",
       "      <td>0.048650</td>\n",
       "      <td>0.154578</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>{'clf__max_depth': 1, 'clf__max_features': 0.1...</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.684685</td>\n",
       "      <td>0.055535</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.146635</td>\n",
       "      <td>0.092694</td>\n",
       "      <td>0.342471</td>\n",
       "      <td>0.016429</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'clf__max_depth': 1, 'clf__max_features': 0.1...</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.022067</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.452406</td>\n",
       "      <td>0.030625</td>\n",
       "      <td>0.040977</td>\n",
       "      <td>0.004080</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'clf__max_depth': 1, 'clf__max_features': 0.2...</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.058385</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.248067</td>\n",
       "      <td>0.025732</td>\n",
       "      <td>0.164572</td>\n",
       "      <td>0.003089</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'clf__max_depth': 1, 'clf__max_features': 0.2...</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.693694</td>\n",
       "      <td>0.050963</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>4.785576</td>\n",
       "      <td>0.098413</td>\n",
       "      <td>0.138254</td>\n",
       "      <td>0.004494</td>\n",
       "      <td>25</td>\n",
       "      <td>0.9</td>\n",
       "      <td>500</td>\n",
       "      <td>{'clf__max_depth': 25, 'clf__max_features': 0....</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.058385</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>9.190057</td>\n",
       "      <td>0.309714</td>\n",
       "      <td>0.283838</td>\n",
       "      <td>0.031826</td>\n",
       "      <td>25</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'clf__max_depth': 25, 'clf__max_features': 0....</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.738739</td>\n",
       "      <td>0.050963</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.948787</td>\n",
       "      <td>0.005247</td>\n",
       "      <td>0.031316</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>{'clf__max_depth': 25, 'clf__max_features': 1....</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.720721</td>\n",
       "      <td>0.045937</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>5.220186</td>\n",
       "      <td>0.253196</td>\n",
       "      <td>0.147428</td>\n",
       "      <td>0.008824</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>{'clf__max_depth': 25, 'clf__max_features': 1....</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.058385</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>9.219772</td>\n",
       "      <td>0.559229</td>\n",
       "      <td>0.175572</td>\n",
       "      <td>0.064811</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'clf__max_depth': 25, 'clf__max_features': 1....</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.711712</td>\n",
       "      <td>0.077498</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.314154      0.006339         0.033314        0.003396   \n",
       "1         1.895245      0.048650         0.154578        0.003769   \n",
       "2         4.146635      0.092694         0.342471        0.016429   \n",
       "3         0.452406      0.030625         0.040977        0.004080   \n",
       "4         2.248067      0.025732         0.164572        0.003089   \n",
       "..             ...           ...              ...             ...   \n",
       "115       4.785576      0.098413         0.138254        0.004494   \n",
       "116       9.190057      0.309714         0.283838        0.031826   \n",
       "117       0.948787      0.005247         0.031316        0.001698   \n",
       "118       5.220186      0.253196         0.147428        0.008824   \n",
       "119       9.219772      0.559229         0.175572        0.064811   \n",
       "\n",
       "    param_clf__max_depth param_clf__max_features param_clf__n_estimators  \\\n",
       "0                      1                     0.1                     100   \n",
       "1                      1                     0.1                     500   \n",
       "2                      1                     0.1                    1000   \n",
       "3                      1                     0.2                     100   \n",
       "4                      1                     0.2                     500   \n",
       "..                   ...                     ...                     ...   \n",
       "115                   25                     0.9                     500   \n",
       "116                   25                     0.9                    1000   \n",
       "117                   25                     1.0                     100   \n",
       "118                   25                     1.0                     500   \n",
       "119                   25                     1.0                    1000   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "0    {'clf__max_depth': 1, 'clf__max_features': 0.1...           0.648649   \n",
       "1    {'clf__max_depth': 1, 'clf__max_features': 0.1...           0.621622   \n",
       "2    {'clf__max_depth': 1, 'clf__max_features': 0.1...           0.648649   \n",
       "3    {'clf__max_depth': 1, 'clf__max_features': 0.2...           0.648649   \n",
       "4    {'clf__max_depth': 1, 'clf__max_features': 0.2...           0.621622   \n",
       "..                                                 ...                ...   \n",
       "115  {'clf__max_depth': 25, 'clf__max_features': 0....           0.702703   \n",
       "116  {'clf__max_depth': 25, 'clf__max_features': 0....           0.702703   \n",
       "117  {'clf__max_depth': 25, 'clf__max_features': 1....           0.675676   \n",
       "118  {'clf__max_depth': 25, 'clf__max_features': 1....           0.675676   \n",
       "119  {'clf__max_depth': 25, 'clf__max_features': 1....           0.702703   \n",
       "\n",
       "     split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0             0.729730           0.783784         0.720721        0.055535   \n",
       "1             0.675676           0.756757         0.684685        0.055535   \n",
       "2             0.675676           0.702703         0.675676        0.022067   \n",
       "3             0.675676           0.783784         0.702703        0.058385   \n",
       "4             0.729730           0.729730         0.693694        0.050963   \n",
       "..                 ...                ...              ...             ...   \n",
       "115           0.675676           0.810811         0.729730        0.058385   \n",
       "116           0.702703           0.810811         0.738739        0.050963   \n",
       "117           0.702703           0.783784         0.720721        0.045937   \n",
       "118           0.648649           0.783784         0.702703        0.058385   \n",
       "119           0.621622           0.810811         0.711712        0.077498   \n",
       "\n",
       "     rank_test_score  \n",
       "0                 48  \n",
       "1                111  \n",
       "2                117  \n",
       "3                 95  \n",
       "4                106  \n",
       "..               ...  \n",
       "115               17  \n",
       "116                6  \n",
       "117               48  \n",
       "118               95  \n",
       "119               72  \n",
       "\n",
       "[120 rows x 14 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare a hyperparameter grid\n",
    "param_grid = {\n",
    "    \"clf__n_estimators\": [100, 500, 1000],\n",
    "    \"clf__max_depth\": [1, 5, 10, 25],\n",
    "    \"clf__max_features\": [*np.arange(0.1, 1.1, 0.1)],\n",
    "}\n",
    "\n",
    "# Perform grid search, fit it, and print score\n",
    "grid = GridSearchCV(pipeline, param_grid=param_grid, cv=3, n_jobs=-1, verbose=1000)\n",
    "grid.fit(gene_train,drug_train)\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6486486486486487"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "grid.best_params_\n",
    "\n",
    "drug_pred = grid.predict(gene_test)\n",
    "# View The Accuracy Of Our Full Feature Model\n",
    "accuracy_score(drug_test, drug_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00376651 0.00348005 0.00488924 0.00961368 0.00394305 0.00267516\n",
      " 0.00418144 0.00621398 0.00298036 0.00491051 0.00404731 0.00267488\n",
      " 0.00345139 0.00367254 0.00534313 0.00987261 0.00323257 0.00453896\n",
      " 0.00396323 0.00415115 0.0134422  0.00399638 0.00272394 0.00673193\n",
      " 0.04221261 0.00279753 0.00293409 0.0026749  0.00322098 0.00259753\n",
      " 0.00327285 0.0028795  0.00267043 0.00411553 0.00359416 0.00254335\n",
      " 0.00380276 0.00342334 0.00315615 0.00924198 0.00655549 0.00772593\n",
      " 0.00371204 0.00266717 0.00439133 0.00299462 0.00295476 0.00292623\n",
      " 0.00455489 0.0031763  0.00282655 0.0033475  0.00375853 0.00506828\n",
      " 0.00335284 0.00345949 0.00327207 0.00466305 0.00419797 0.00517828\n",
      " 0.00691618 0.00304042 0.00338471 0.00282134 0.00255516 0.00300731\n",
      " 0.00322851 0.00232748 0.00212551 0.00333813 0.00285093 0.00292955\n",
      " 0.00456859 0.00459421 0.00262881 0.00291949 0.00411507 0.00439948\n",
      " 0.00213753 0.00483945 0.00440438 0.00347989 0.00207836 0.00237288\n",
      " 0.00259679 0.00219001 0.00423628 0.00251034 0.00629739 0.00704821\n",
      " 0.01052171 0.00342077 0.00322391 0.00471447 0.00354998 0.00497294\n",
      " 0.0041588  0.00290044 0.00434708 0.00242647 0.00685329 0.00270542\n",
      " 0.00336323 0.00204712 0.00518872 0.00743605 0.00209443 0.00171701\n",
      " 0.00240771 0.01485939 0.00234681 0.00367957 0.00364502 0.00388902\n",
      " 0.00226781 0.00696533 0.00272164 0.00395326 0.00423321 0.00180678\n",
      " 0.0027411  0.00926435 0.00437099 0.00286217 0.00467796 0.0049351\n",
      " 0.00174232 0.00768321 0.0031918  0.00953271 0.00295776 0.00334908\n",
      " 0.00354933 0.00174634 0.00210437 0.0024591  0.00356975 0.00544356\n",
      " 0.00466949 0.00401403 0.00234055 0.00228335 0.00522055 0.00306718\n",
      " 0.00198266 0.00296276 0.00204087 0.00376351 0.00321907 0.00279605\n",
      " 0.00326715 0.00457179 0.00245697 0.0042612  0.00333373 0.00580701\n",
      " 0.00522265 0.00315189 0.00303824 0.00241234 0.00710681 0.00354185\n",
      " 0.00180177 0.01045522 0.0036302  0.00210348 0.00503351 0.00259937\n",
      " 0.00304967 0.0042055  0.00248692 0.00805313 0.00286498 0.00283562\n",
      " 0.00311826 0.00186236 0.00263168 0.00262851 0.00449538 0.00621617\n",
      " 0.00362352 0.00461357 0.00226843 0.00266695 0.00329286 0.00395999\n",
      " 0.00207863 0.00495728 0.00151064 0.00317961 0.00262796 0.00290869\n",
      " 0.00548796 0.00210806 0.00328152 0.00253191 0.00353277 0.00533689\n",
      " 0.00338966 0.00167822 0.00333595 0.00648617 0.00254857 0.00422348\n",
      " 0.00208421 0.00392897 0.00321947 0.00354439 0.00280082 0.00873348\n",
      " 0.00221507 0.00196224 0.00596379 0.00395121 0.00367385 0.00252968\n",
      " 0.00306205 0.01040064 0.01246862 0.00283051 0.00287867 0.00286143\n",
      " 0.00252542 0.00302714 0.00255589 0.00268788 0.00364701 0.00440968\n",
      " 0.00339287 0.0106444  0.00321962 0.00241779 0.0039537  0.00278749\n",
      " 0.01863374 0.00670325 0.00235466 0.00473965]\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(gene_train, drug_train)\n",
    "\n",
    "importance=clf.feature_importances_\n",
    "print(importance) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biomedical applications\n",
    "\n",
    "Driven by technological advances, there has recently been a dramatic increase in availability of biomedical data. Machine learning approaches are well suited to take advantage of this data and have been widely applied to many areas of biology. \n",
    "\n",
    "Example of these applications are genome annotation, biomarker identification, systems biology, genome data analysis, protein  function  prediction, protein  structure prediction, protein localization prediction, identification of protein interactions and drug discovery.\n",
    "\n",
    "SVM and RF methods are among the most popular machine learning methods applied in bioinformatics or computational biology.\n",
    "\n",
    "Perform a literature search and find a biomedical study in which SVM or RF is applied to obtain certain insights. <p><font color='#770a0a'>Explain the motivation behind using that specific algorithm in the study.\n",
    "</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the study named \"Detection of Life-Threatening Arrhythmias Using Feature Selection and Support Vector Machines\" [1] the authors chose to use an SVM algorithm because it has been successfully used in a wide number of practical classification problems, due to their good generalization capability and to the structural risk minimization principle.SVM binary classifiers are sampled-based statistical learning algorithms that construct a maximum margin separating hyperplane. The best separating hyperplane should ideally be as far away as possible from any data point to get the best probability of correct classification of new data. Perfectly separating classes might not always be a feasible option.Therefore, when that happens, authors can tune their model to allow for a margin of error.\n",
    "\n",
    "[1] F. Alonso-Atienza, E. Morgado, L. Fernández-Martínez, A. García-Alberola and J. L. Rojo-Álvarez, \"Detection of Life-Threatening Arrhythmias Using Feature Selection and Support Vector Machines,\" in IEEE Transactions on Biomedical Engineering, vol. 61, no. 3, pp. 832-840, March 2014, doi: 10.1109/TBME.2013.2290800."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "11bc3faa42291987dff8047a7fe728de8bffd01e5e426b1fc111590146fa91bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
